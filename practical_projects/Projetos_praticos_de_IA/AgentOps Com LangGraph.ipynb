{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceito de AgentOps e Aplicação no LangGraph\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O **AgentOps** é um conceito e uma biblioteca que emergiu para abordar os desafios de **observabilidade**, **rastreabilidade** e **confiabilidade** em sistemas de inteligência artificial, especialmente aqueles que utilizam agentes autônomos baseados em modelos de linguagem de grande porte (LLMs). Com o crescente uso de agentes que realizam tarefas complexas e multietapas, tornou-se essencial monitorar e entender o comportamento desses sistemas para garantir que eles operem conforme o esperado.\n",
    "\n",
    "Neste texto, exploraremos:\n",
    "\n",
    "- O **conceito de AgentOps** e como a biblioteca correspondente auxilia no monitoramento de agentes de IA.\n",
    "- A **aplicação do AgentOps** em um fluxo de trabalho construído com o **LangGraph**, integrando funcionalidades como busca na web com o **Tavily**.\n",
    "- Uma descrição detalhada de **como o fluxo de trabalho do script** funciona, incluindo cada etapa e sua finalidade.\n",
    "\n",
    "## Conceito de AgentOps\n",
    "\n",
    "### O que é AgentOps?\n",
    "\n",
    "**AgentOps** é uma extensão dos conceitos de **DevOps** e **MLOps**, mas direcionada especificamente para agentes autônomos baseados em modelos de linguagem. Seu objetivo é fornecer ferramentas e práticas para:\n",
    "\n",
    "- **Observabilidade**: Monitorar em tempo real o comportamento dos agentes, incluindo decisões tomadas, ações realizadas e dados processados.\n",
    "- **Rastreabilidade**: Manter registros detalhados das operações dos agentes para fins de auditoria, depuração e otimização.\n",
    "- **Confiabilidade**: Garantir que os agentes operem de maneira consistente e previsível, atendendo aos requisitos de desempenho e segurança.\n",
    "\n",
    "### Por que AgentOps é importante?\n",
    "\n",
    "Com a complexidade crescente dos agentes de IA, surgem desafios como:\n",
    "\n",
    "- **Decisões**: Os modelos de linguagem podem tomar decisões que não são facilmente compreensíveis por humanos.\n",
    "- **Erros Difíceis de Depurar**: Sem rastreamento adequado, é difícil identificar onde e por que um erro ocorreu.\n",
    "- **Regulamentações e Compliance**: Áreas como saúde e finanças exigem conformidade com regulamentações, o que requer rastreabilidade das ações dos agentes.\n",
    "\n",
    "### Funcionalidades da Biblioteca AgentOps\n",
    "\n",
    "A biblioteca AgentOps oferece:\n",
    "\n",
    "- **Decoradores para Registro de Ações**: Permitem decorar funções e métodos para registrar automaticamente entradas, saídas e metadados.\n",
    "- **Sessões de Agente**: Agrupam eventos e ações dentro de uma sessão para facilitar o monitoramento e a análise.\n",
    "- **Registro de Eventos**: Suporta diferentes tipos de eventos, como ações, erros e ferramentas utilizadas.\n",
    "- **Integração com Dashboards**: Oferece visualização das métricas e logs em um dashboard centralizado.\n",
    "\n",
    "#### Principais Componentes\n",
    "\n",
    "- `init()`: Inicializa o AgentOps e configura parâmetros globais, como chaves de API e tags.\n",
    "- `end_session()`: Encerra a sessão atual, permitindo que os dados sejam consolidados.\n",
    "- `@record_action`: Decorador que registra a execução de uma função como uma ação, capturando parâmetros e resultados.\n",
    "- `@track_agent`: Decorador que associa ações a um agente específico.\n",
    "- `record()`: Função que permite registrar eventos manualmente, como erros ou eventos personalizados.\n",
    "\n",
    "### Benefícios do AgentOps\n",
    "\n",
    "- **Transparência**: Fornece visibilidade sobre o que o agente está fazendo em cada etapa.\n",
    "- **Depuração Facilitada**: Com logs detalhados, é mais fácil identificar e corrigir erros.\n",
    "- **Otimização**: Métricas de desempenho ajudam a identificar gargalos e oportunidades de melhoria.\n",
    "- **Compliance**: A rastreabilidade ajuda a atender a requisitos regulatórios, mantendo registros das operações.\n",
    "\n",
    "## Aplicação do AgentOps no LangGraph\n",
    "\n",
    "### O que é o LangGraph?\n",
    "\n",
    "O **LangGraph** é uma ferramenta que permite a construção de fluxos de trabalho complexos utilizando modelos de linguagem. Ele facilita a definição de estados e transições em um grafo, onde cada nó representa uma etapa do processamento.\n",
    "\n",
    "### Integração do AgentOps com o LangGraph\n",
    "\n",
    "Ao combinar o AgentOps com o LangGraph, obtém-se um fluxo de trabalho robusto, observável e rastreável. A integração é feita decorando as funções (nós do grafo) com os decoradores do AgentOps, permitindo que cada ação seja monitorada e registrada.\n",
    "\n",
    "#### Passos para a Integração\n",
    "\n",
    "1. **Inicialização do AgentOps**: Configura chaves de API e parâmetros globais.\n",
    "   ```python\n",
    "   init(api_key='SUA_CHAVE_AGENTOPS', default_tags=[\"langgraph-agent\"])\n",
    "   ```\n",
    "\n",
    "2. **Definição das Funções do Fluxo**: Cada função representa uma etapa do processamento e é decorada com `@record_action`.\n",
    "   ```python\n",
    "   @record_action(\"web_search\")\n",
    "   def web_search(state: AgentState) -> AgentState:\n",
    "       # Implementação da função\n",
    "   ```\n",
    "\n",
    "3. **Construção do Grafo**: Utiliza o LangGraph para definir os nós e as transições.\n",
    "   ```python\n",
    "   builder = StateGraph(AgentState)\n",
    "   builder.add_node(\"web_search\", web_search)\n",
    "   # Adicionar outros nós e arestas\n",
    "   ```\n",
    "\n",
    "4. **Execução do Fluxo**: O grafo é compilado e executado, e ao final, a sessão do AgentOps é encerrada.\n",
    "   ```python\n",
    "   final_state = graph.invoke(initial_state)\n",
    "   end_session(\"Success\", \"Fluxo concluído com sucesso\")\n",
    "   ```\n",
    "\n",
    "### Benefícios da Aplicação\n",
    "\n",
    "- **Observabilidade Detalhada**: Cada etapa do fluxo é monitorada, permitindo uma visão completa do processamento.\n",
    "- **Detecção de Erros**: Exceções são capturadas e registradas, facilitando a identificação de problemas.\n",
    "- **Métricas de Desempenho**: Dados sobre tempo de execução, uso de recursos e custos são coletados.\n",
    "- **Rastreabilidade**: Mantém um histórico completo das ações, essencial para auditorias e compliance.\n",
    "\n",
    "## Fluxo de Trabalho Total do Script\n",
    "\n",
    "### Objetivo do Script\n",
    "\n",
    "Criar um agente que:\n",
    "\n",
    "- Recebe uma consulta do usuário.\n",
    "- Realiza uma busca real na web utilizando o Tavily.\n",
    "- Resume os resultados obtidos.\n",
    "- Gera uma resposta final detalhada.\n",
    "- Monitora e registra todas as ações utilizando o AgentOps.\n",
    "\n",
    "### Descrição Detalhada do Fluxo\n",
    "\n",
    "1. **Inicialização do Ambiente**:\n",
    "   - Importação das bibliotecas necessárias.\n",
    "   - Carregamento das variáveis de ambiente (chaves de API).\n",
    "   - Configuração do logging para depuração.\n",
    "\n",
    "2. **Definição do Estado do Agente**:\n",
    "   - Utiliza `TypedDict` para definir `AgentState`, que armazena:\n",
    "     - `query`: A consulta do usuário.\n",
    "     - `search_results`: Resultados da busca.\n",
    "     - `summary`: Resumo dos resultados.\n",
    "     - `final_answer`: Resposta final gerada.\n",
    "\n",
    "3. **Inicialização dos Componentes**:\n",
    "   - Modelo da OpenAI (`ChatOpenAI`) para geração de texto.\n",
    "   - Tavily Search (`TavilySearchResults`) para busca na web.\n",
    "\n",
    "4. **Definição das Funções do Fluxo**:\n",
    "\n",
    "   #### a. Função `web_search`:\n",
    "   - **Responsabilidade**: Realizar a busca na web utilizando o Tavily.\n",
    "   - **Implementação**:\n",
    "     - Decoração com `@record_action(\"web_search\")`.\n",
    "     - Tenta obter os resultados da busca.\n",
    "     - Processa os resultados, formatando-os adequadamente.\n",
    "     - Em caso de erro, registra um `ErrorEvent` no AgentOps.\n",
    "   - **Fluxo**:\n",
    "     ```python\n",
    "     @record_action(\"web_search\")\n",
    "     def web_search(state: AgentState) -> AgentState:\n",
    "         # Implementação\n",
    "     ```\n",
    "\n",
    "   #### b. Função `summarize_results`:\n",
    "   - **Responsabilidade**: Resumir os resultados da busca em um parágrafo conciso.\n",
    "   - **Implementação**:\n",
    "     - Decoração com `@record_action(\"summarize_results\")`.\n",
    "     - Cria um prompt para o modelo resumir as informações.\n",
    "     - Atualiza o estado com o resumo obtido.\n",
    "   - **Fluxo**:\n",
    "     ```python\n",
    "     @record_action(\"summarize_results\")\n",
    "     def summarize_results(state: AgentState) -> AgentState:\n",
    "         # Implementação\n",
    "     ```\n",
    "\n",
    "   #### c. Função `generate_answer`:\n",
    "   - **Responsabilidade**: Gerar a resposta final baseada na consulta e no resumo.\n",
    "   - **Implementação**:\n",
    "     - Decoração com `@record_action(\"generate_answer\")`.\n",
    "     - Cria um prompt para o modelo gerar a resposta final.\n",
    "     - Atualiza o estado com a resposta gerada.\n",
    "   - **Fluxo**:\n",
    "     ```python\n",
    "     @record_action(\"generate_answer\")\n",
    "     def generate_answer(state: AgentState) -> AgentState:\n",
    "         # Implementação\n",
    "     ```\n",
    "\n",
    "5. **Construção do Grafo**:\n",
    "   - Criação de um `StateGraph` com o estado definido.\n",
    "   - Adição dos nós correspondentes às funções.\n",
    "   - Definição das arestas que conectam os nós, estabelecendo a ordem das etapas.\n",
    "   - Compilação do grafo para execução.\n",
    "\n",
    "   ```python\n",
    "   builder = StateGraph(AgentState)\n",
    "   builder.add_node(\"web_search\", web_search)\n",
    "   builder.add_node(\"summarize_results\", summarize_results)\n",
    "   builder.add_node(\"generate_answer\", generate_answer)\n",
    "   # Adicionar arestas e compilar\n",
    "   ```\n",
    "\n",
    "6. **Execução do Fluxo de Trabalho**:\n",
    "\n",
    "   - Definição da função `execute_workflow` que:\n",
    "     - Inicializa o estado com a consulta do usuário.\n",
    "     - Executa o grafo com o estado inicial.\n",
    "     - Encerra a sessão do AgentOps, registrando o sucesso.\n",
    "     - Retorna a resposta final.\n",
    "\n",
    "   ```python\n",
    "   def execute_workflow(query: str) -> str:\n",
    "       # Implementação\n",
    "   ```\n",
    "\n",
    "7. **Exemplo de Uso**:\n",
    "\n",
    "   - Define uma consulta de exemplo.\n",
    "   - Chama `execute_workflow` com a consulta.\n",
    "   - Imprime a resposta final.\n",
    "\n",
    "   ```python\n",
    "   query = \"Quais são os avanços recentes em inteligência artificial na área de saúde?\"\n",
    "   answer = execute_workflow(query)\n",
    "   print(\"Resposta Final:\\n\")\n",
    "   print(answer)\n",
    "   ```\n",
    "\n",
    "### Fluxo Completo das Etapas\n",
    "\n",
    "1. **Recebimento da Consulta**:\n",
    "   - O usuário fornece uma pergunta ou tópico de interesse.\n",
    "\n",
    "2. **Busca na Web (`web_search`)**:\n",
    "   - O agente utiliza o Tavily para realizar uma busca real na web.\n",
    "   - Os resultados são processados e armazenados no estado.\n",
    "\n",
    "3. **Resumo dos Resultados (`summarize_results`)**:\n",
    "   - O agente cria um prompt para o modelo resumir os resultados.\n",
    "   - O resumo é gerado e armazenado.\n",
    "\n",
    "4. **Geração da Resposta Final (`generate_answer`)**:\n",
    "   - O agente combina a consulta original e o resumo.\n",
    "   - Utiliza o modelo para gerar uma resposta detalhada.\n",
    "   - A resposta é armazenada no estado.\n",
    "\n",
    "5. **Encerramento e Registro**:\n",
    "   - A sessão do AgentOps é encerrada, registrando o sucesso e o motivo.\n",
    "   - Todas as ações e eventos são registrados para análise posterior.\n",
    "\n",
    "6. **Retorno da Resposta**:\n",
    "   - A resposta final é retornada e exibida ao usuário.\n",
    "\n",
    "### Como o AgentOps Monitora o Fluxo\n",
    "\n",
    "- **Ações Registradas**: Cada função decorada com `@record_action` registra:\n",
    "  - Parâmetros de entrada.\n",
    "  - Resultado da função.\n",
    "  - Tempo de execução.\n",
    "- **Eventos de Erro**: Se ocorrer uma exceção, um `ErrorEvent` é registrado, incluindo detalhes da exceção.\n",
    "- **Sessão do Agente**: Agrupa todos os eventos e ações em uma sessão, facilitando a análise.\n",
    "- **Métricas Coletadas**:\n",
    "  - Uso de tokens nas chamadas ao modelo.\n",
    "  - Latência das operações.\n",
    "  - Custos associados às chamadas de API.\n",
    "\n",
    "### Benefícios do Fluxo de Trabalho\n",
    "\n",
    "- **Atualidade das Informações**: Ao utilizar o Tavily, o agente acessa informações recentes da web.\n",
    "- **Eficiência**: O uso do LangGraph permite organizar o fluxo de forma modular e clara.\n",
    "- **Transparência**: O AgentOps fornece visibilidade total sobre o que o agente está fazendo.\n",
    "- **Confiabilidade**: Com monitoramento contínuo, é possível garantir que o agente opere conforme o esperado.\n",
    "- **Escalabilidade**: A estrutura permite adicionar novas funcionalidades ou expandir o fluxo conforme necessário.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "A combinação do **AgentOps** com o **LangGraph** resulta em um agente poderoso, capaz de realizar tarefas complexas com eficiência e transparência. Ao integrar funcionalidades como busca real na web e monitoramento detalhado, obtemos um sistema que não só atende às necessidades imediatas do usuário, mas também proporciona uma base sólida para manutenção, otimização e expansão futuras.\n",
    "\n",
    "**Resumo dos Pontos-Chave**:\n",
    "\n",
    "- **AgentOps**: Fornece ferramentas para observabilidade e rastreabilidade de agentes de IA.\n",
    "- **LangGraph**: Permite construir fluxos de trabalho estruturados utilizando modelos de linguagem.\n",
    "- **Integração**: Decoradores do AgentOps são usados nas funções do LangGraph para monitorar o fluxo.\n",
    "- **Fluxo de Trabalho**: Inclui busca na web, resumo de informações e geração de respostas detalhadas.\n",
    "- **Benefícios**:\n",
    "  - Transparência total sobre as operações do agente.\n",
    "  - Possibilidade de depuração e otimização com base em dados reais.\n",
    "  - Atendimento a requisitos de compliance e auditoria.\n",
    "\n",
    "Ao implementar tais soluções, estamos avançando na direção de sistemas de IA mais confiáveis, eficientes e alinhados com as necessidades humanas, mantendo a capacidade de evoluir e se adaptar a novos desafios e demandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentops in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (0.3.18)\n",
      "Requirement already satisfied: langgraph in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (0.2.38)\n",
      "Requirement already satisfied: langchain_openai in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain_community in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: tavily-python in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (0.5.0)\n",
      "Requirement already satisfied: python-dotenv in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from agentops) (2.32.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from agentops) (5.9.8)\n",
      "Requirement already satisfied: packaging==23.2 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from agentops) (23.2)\n",
      "Requirement already satisfied: termcolor>=2.3.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from agentops) (2.5.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.3 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from agentops) (6.0.2)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langgraph) (0.3.19)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langgraph) (2.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langgraph) (0.1.33)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_openai) (1.51.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (0.1.135)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (2.6.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: httpx in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from tavily-python) (0.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.7)\n",
      "Requirement already satisfied: anyio in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpx->tavily-python) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpx->tavily-python) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpx->tavily-python) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpx->tavily-python) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.6.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install agentops langgraph langchain_openai langchain_community tavily-python python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from agentops import record_action, track_agent, init, end_session, record, ActionEvent, ToolEvent, ErrorEvent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar a chave de API da OpenAI\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')  # Defina sua chave no arquivo .env\n",
    "\n",
    "# Configurar a chave de API do AgentOps\n",
    "os.environ['AGENTOPS_API_KEY'] = os.getenv('AGENTOPS_API_KEY')  # Defina sua chave no arquivo .env\n",
    "\n",
    "# Configurar a chave de API do Tavily\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')  # Defina sua chave no arquivo .env\n",
    "\n",
    "# Configurar o nível de log para DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/agentops/json HTTP/11\" 200 26744\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 \"POST /v2/create_session HTTP/11\" 200 311\n",
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=77a92f0c-f5ee-4c53-b9a7-5272d17a7914\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<agentops.session.Session at 0x76ce758bbe00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o AgentOps\n",
    "init(api_key=os.environ['AGENTOPS_API_KEY'], default_tags=[\"langgraph-agent\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    search_results: str\n",
    "    summary: str\n",
    "    final_answer: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/anderson/miniconda3/envs/nl2sqlduckdb/lib/python3.13/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o modelo da OpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Inicializar o Tavily Search\n",
    "tavily_search = TavilySearchResults(max_results=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@record_action(\"web_search\")\n",
    "def web_search(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        # Realizar a busca utilizando o Tavily\n",
    "        search_results = tavily_search.invoke(state[\"query\"])\n",
    "        # Verificar o formato dos resultados\n",
    "        if isinstance(search_results, list) and all(isinstance(r, str) for r in search_results):\n",
    "            # Se for uma lista de strings\n",
    "            formatted_results = \"\\n\".join(search_results)\n",
    "        elif isinstance(search_results, list) and all(isinstance(r, dict) for r in search_results):\n",
    "            # Se for uma lista de dicionários\n",
    "            formatted_results = \"\\n\".join([f\"{r.get('title', '')}: {r.get('snippet', r.get('content', ''))}\" for r in search_results])\n",
    "        else:\n",
    "            formatted_results = str(search_results)\n",
    "        state[\"search_results\"] = formatted_results\n",
    "    except Exception as e:\n",
    "        # Registrar um evento de erro no AgentOps\n",
    "        record(ErrorEvent(exception=e))\n",
    "        state[\"search_results\"] = f\"Erro ao realizar a busca: {str(e)}\"\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@record_action(\"summarize_results\")\n",
    "def summarize_results(state: AgentState) -> AgentState:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Resuma as seguintes informações em um parágrafo conciso em português.\\n\\nInformações: {search_results}\"\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    summary = chain.invoke({\"search_results\": state[\"search_results\"]}).content\n",
    "    state[\"summary\"] = summary\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@record_action(\"generate_answer\")\n",
    "def generate_answer(state: AgentState) -> AgentState:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Com base na sua pergunta '{query}' e nas informações resumidas abaixo, forneça uma resposta detalhada em português, utilizando bullet points quando necessário.\\n\\nResumo: {summary}\"\n",
    "    )\n",
    "    chain = prompt | model\n",
    "    final_answer = chain.invoke({\"query\": state[\"query\"], \"summary\": state[\"summary\"]}).content\n",
    "    state[\"final_answer\"] = final_answer\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do grafo\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Adicionar nós\n",
    "builder.add_node(\"web_search\", web_search)\n",
    "builder.add_node(\"summarize_results\", summarize_results)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Adicionar arestas\n",
    "builder.add_edge(START, \"web_search\")\n",
    "builder.add_edge(\"web_search\", \"summarize_results\")\n",
    "builder.add_edge(\"summarize_results\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# Definir ponto de entrada\n",
    "builder.set_entry_point(\"web_search\")\n",
    "\n",
    "# Compilar o grafo\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_workflow(query: str) -> str:\n",
    "    # Estado inicial\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"search_results\": \"\",\n",
    "        \"summary\": \"\",\n",
    "        \"final_answer\": \"\"\n",
    "    }\n",
    "\n",
    "    # Executar o grafo\n",
    "    final_state = graph.invoke(initial_state)\n",
    "\n",
    "    # Encerrar a sessão do AgentOps com sucesso\n",
    "    end_session(\"Success\", \"Fluxo concluído com sucesso\")\n",
    "\n",
    "    return final_state[\"final_answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.tavily.com:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.tavily.com:443 \"POST /search HTTP/11\" 200 2670\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Resuma as seguintes informações em um parágrafo conciso em português.\\n\\nInformações: : Criada por Anderson Amaral, especialista em ciência de dados e inteligência artificial com vasta experiência no mercado, a Scoras Academy é voltada para profissionais e entusiastas que buscam se destacar e crescer em suas carreiras, estudando o que há de mais avançado na área: agentes de IA e Agentic-workflows. Agora, na Scoras Academy, Anderson compartilha seu conhecimento por meio de cursos que cobrem desde fundamentos até técnicas avançadas, sempre com foco na aplicação prática. Na Scoras Academy, oferecemos um modelo de assinatura focado em formação continuada para que você esteja sempre à frente no mundo da tecnologia e inteligência artificial. Ao assinar a Scoras Academy Mensal ou Anual, você tem acesso ilimitado pelo período da sua assinatura a todos os cursos disponíveis na plataforma.\\n: Seja bem-vindo à Scoras Academy, o espaço de aprendizado ideal para quem deseja transformar conhecimento em prática! Criada por Anderson Amaral, especialista em ciência de dados e inteligência artificial com vasta experiência no mercado, a Scoras Academy é voltada para profissionais e entusiastas que buscam se destacar e crescer em suas carreiras, estudando o que há de mais avançado na área: agentes de IA e workflows agentic. Agora, na Scoras Academy, Anderson compartilha seu conhecimento por meio de cursos que cobrem desde fundamentos até técnicas avançadas, sempre com foco na aplicação prática. - Conteúdo Exclusivo: Aprenda diretamente com Anderson Amaral por meio de aulas dinâmicas e práticas, que abordam desde conceitos básicos até técnicas avançadas. Participe da Scoras Academy e inicie sua jornada de aprendizado com Anderson Amaral.\\n: Transforme sua carreira com os cursos práticos da Scoras Academy! ... Isso permite que consultas mais simples sejam direcionadas a modelos mais baratos 💸, enquanto as mais complexas são enviadas para modelos mais avançados 🚀, otimizando o equilíbrio entre custo e desempenho. ⚖️ Principais Benefícios do LLM Routing: 💰 Redução', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x76ce75527b60>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x76ce75631eb0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x76ce75544910>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 17:36:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'scoras-7qey7t'), (b'openai-processing-ms', b'2042'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999447'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_cbbc51f8f0a5ed6bd8240e4aad157a76'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1CjIIjjyRI7bGY.IUEh73u9Ya7WPlgg5sw7ejqmQhxs-1732383361-1.0.1.1-QZBo6h8ONQAYx5ywUYMgkL2.J54CgJvY6i8WCo6csUA9W.UnEWkKeZgBiCXv6ughbX1j4zP9RnBqpGduF09tgg; path=/; expires=Sat, 23-Nov-24 18:06:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kZV1b9R4TZZdbypJ5OunYRA5TLYSzQBCEjV.Ckgnu80-1732383361990-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e72eb3e9bb07def-GRU'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sat, 23 Nov 2024 17:36:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'scoras-7qey7t'), ('openai-processing-ms', '2042'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9999447'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_cbbc51f8f0a5ed6bd8240e4aad157a76'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=1CjIIjjyRI7bGY.IUEh73u9Ya7WPlgg5sw7ejqmQhxs-1732383361-1.0.1.1-QZBo6h8ONQAYx5ywUYMgkL2.J54CgJvY6i8WCo6csUA9W.UnEWkKeZgBiCXv6ughbX1j4zP9RnBqpGduF09tgg; path=/; expires=Sat, 23-Nov-24 18:06:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kZV1b9R4TZZdbypJ5OunYRA5TLYSzQBCEjV.Ckgnu80-1732383361990-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e72eb3e9bb07def-GRU'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_cbbc51f8f0a5ed6bd8240e4aad157a76\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': \"Com base na sua pergunta 'Quais são os cursos da scoras academy?' e nas informações resumidas abaixo, forneça uma resposta detalhada em português, utilizando bullet points quando necessário.\\n\\nResumo: A Scoras Academy, fundada por Anderson Amaral, especialista em ciência de dados e inteligência artificial, é uma plataforma de aprendizado destinada a profissionais e entusiastas que desejam se destacar em suas carreiras, focando em agentes de IA e workflows agentic. A academia oferece cursos que vão desde fundamentos até técnicas avançadas, sempre com ênfase na aplicação prática. Com um modelo de assinatura mensal ou anual, os assinantes têm acesso ilimitado a todos os cursos disponíveis, permitindo uma formação continuada e atualizada no campo da tecnologia e inteligência artificial.\", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 23 Nov 2024 17:36:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'scoras-7qey7t'), (b'openai-processing-ms', b'5533'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999779'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'1ms'), (b'x-request-id', b'req_4a149082f34a316b11eadfa4b691ec55'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e72eb4d0c7b7def-GRU'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 23 Nov 2024 17:36:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'scoras-7qey7t', 'openai-processing-ms': '5533', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999779', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '1ms', 'x-request-id': 'req_4a149082f34a316b11eadfa4b691ec55', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e72eb4d0c7b7def-GRU', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_4a149082f34a316b11eadfa4b691ec55\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 \"POST /v2/create_events HTTP/11\" 200 9\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 \"POST /v2/update_session HTTP/11\" 200 142\n",
      "🖇 AgentOps: Session Stats - \u001b[1mDuration:\u001b[0m 12.8s | \u001b[1mCost:\u001b[0m $0.000427 | \u001b[1mLLMs:\u001b[0m 2 | \u001b[1mTools:\u001b[0m 0 | \u001b[1mActions:\u001b[0m 3 | \u001b[1mErrors:\u001b[0m 0\n",
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=77a92f0c-f5ee-4c53-b9a7-5272d17a7914\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 \"POST /v2/create_events HTTP/11\" 200 9\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.agentops.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.agentops.ai:443 \"POST /v2/create_events HTTP/11\" 200 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta Final:\n",
      "\n",
      "A Scoras Academy é uma plataforma de aprendizado inovadora, ideal para profissionais e entusiastas que buscam se destacar nas áreas de ciência de dados e inteligência artificial. Fundada por Anderson Amaral, a academia oferece uma variedade de cursos que atendem a diferentes níveis de conhecimento e experiência. Aqui estão os principais detalhes sobre os cursos disponíveis:\n",
      "\n",
      "### Cursos Oferecidos\n",
      "- **Fundamentos de Ciência de Dados**: Introdução aos conceitos básicos, ferramentas e técnicas essenciais para a análise de dados.\n",
      "- **Inteligência Artificial**: Abordagem das principais teorias e práticas em IA, incluindo aprendizado de máquina e redes neurais.\n",
      "- **Agentes de IA**: Foco em como criar e implementar agentes inteligentes que podem operar de forma autônoma em diferentes ambientes.\n",
      "- **Workflows Agentic**: Desenvolvimento de habilidades para projetar e gerenciar fluxos de trabalho que utilizam agentes de IA de maneira eficaz.\n",
      "- **Técnicas Avançadas**: Cursos que exploram tópicos mais complexos e especializados, como deep learning, processamento de linguagem natural e visão computacional.\n",
      "\n",
      "### Metodologia\n",
      "- **Ênfase na Aplicação Prática**: Todos os cursos são projetados para que os alunos possam aplicar o conhecimento adquirido em situações reais, promovendo uma aprendizagem mais eficaz.\n",
      "- **Modelo de Assinatura**: Os alunos podem optar por uma assinatura mensal ou anual, que oferece acesso ilimitado a todos os cursos disponíveis na plataforma.\n",
      "\n",
      "### Benefícios da Scoras Academy\n",
      "- **Formação Continuada**: Os assinantes têm a oportunidade de se manter atualizados com as últimas tendências e tecnologias no campo da ciência de dados e IA.\n",
      "- **Flexibilidade**: A plataforma permite que os alunos aprendam no seu próprio ritmo, adaptando os estudos à sua rotina profissional.\n",
      "- **Comunidade de Aprendizado**: A Scoras Academy promove um ambiente colaborativo, onde os alunos podem interagir, trocar experiências e aprender uns com os outros.\n",
      "\n",
      "Com essa estrutura, a Scoras Academy se posiciona como uma excelente opção para quem deseja aprofundar seus conhecimentos e habilidades em ciência de dados e inteligência artificial, preparando-se para os desafios do mercado de trabalho atual.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de consulta\n",
    "query = \"Quais são os cursos da scoras academy?\"\n",
    "\n",
    "# Executar o fluxo de trabalho\n",
    "answer = execute_workflow(query)\n",
    "\n",
    "# Exibir a resposta final\n",
    "print(\"Resposta Final:\\n\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl2sqlduckdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
