{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Por que ocorrem alucinações?\n",
    "\n",
    "1. **Conhecimento Limitado**: O modelo é treinado em um conjunto de dados fixo e pode não ter informações atualizadas ou precisas sobre todos os tópicos.\n",
    "\n",
    "2. **Generalização Excessiva**: O modelo aprende padrões gerais de linguagem e pode aplicá-los de forma inadequada, criando afirmações que parecem plausíveis, mas são incorretas.\n",
    "\n",
    "3. **Falta de Compreensão Real**: Modelos de linguagem não têm uma compreensão profunda do mundo; eles apenas preveem a próxima palavra com base em padrões estatísticos.\n",
    "\n",
    "4. **Viés nos Dados de Treinamento**: Se os dados de treinamento contêm informações incorretas ou tendenciosas, o modelo pode reproduzir esses erros.\n",
    "\n",
    "5. **Aleatoriedade na Geração**: O uso de amostragem aleatória (como `do_sample=True` e `temperature=0.7`) pode levar a saídas imprevisíveis e potencialmente incorretas.\n",
    "\n",
    "6. **Falta de Verificação de Fatos**: O modelo não tem capacidade de verificar a veracidade das informações que gera.\n",
    "\n",
    "7. **Contexto Limitado**: O modelo considera apenas um contexto limitado (neste caso, até 100 tokens) ao gerar texto, o que pode levar a inconsistências em textos mais longos.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Este exemplo ilustra como modelos de linguagem podem gerar informações que parecem plausíveis, mas podem ser completamente inventadas ou incorretas. Isso destaca a importância de usar esses modelos com cautela, especialmente em aplicações que requerem precisão factual.\n",
    "\n",
    "Ao executar o script, observe como as respostas geradas podem conter informações incorretas ou inventadas, mesmo parecendo convincentes à primeira vista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: O Brasil é famoso por sua culinária, especialmente o prato nacional chamado\n",
      "Texto gerado: O Brasil é famoso por sua culinária, especialmente o prato nacional chamado, en la nombre de la prado de y otras e-pacifica, de los sistios en las emigros, que tiempo de española e como espero, por lo que la vida. Esquirán e una poco un habia de con el su se\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: A capital do Brasil é Brasília, que foi fundada em\n",
      "Texto gerado: A capital do Brasil é Brasília, que foi fundada em siempre a vez esta e una sécurio de la sana de los más. de l'ápida de este puede pálido, con la sudido de uno cambio, por había de á la seguridad.\n",
      "\n",
      "We have worked with the Brazilian government for more than 20 years, and now we have to\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: O animal símbolo do Brasil é o\n",
      "Texto gerado: O animal símbolo do Brasil é ognamente de bocicos do da ella ogado.\n",
      "\n",
      "Para de Pálcula, Pública de la Piedra, púba de las pueblos, o lugar de lo que ha sido o su nueva de deu óncios de eja, para ha puede nel se gente a la piedro de\n",
      "\n",
      "==================================================\n",
      "\n",
      "Prompt: A Amazônia é conhecida por sua biodiversidade, incluindo espécies únicas como\n",
      "Texto gerado: A Amazônia é conhecida por sua biodiversidade, incluindo espécies únicas como sistema. Enferenção è lavoro enfraçe mais aços. Especiale, são más ognes, e-e-fíminas, en vos épareções.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Carregando o modelo e o tokenizador\n",
    "modelo = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizador = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Função para gerar texto\n",
    "def gerar_texto(prompt, max_length=100):\n",
    "    inputs = tokenizador.encode(prompt, return_tensors=\"pt\")\n",
    "    saida = modelo.generate(inputs, max_length=max_length, num_return_sequences=1, \n",
    "                            no_repeat_ngram_size=2, top_k=50, top_p=0.95, \n",
    "                            temperature=0.7, do_sample=True)\n",
    "    return tokenizador.decode(saida[0], skip_special_tokens=True)\n",
    "\n",
    "# Exemplos de prompts que podem levar a alucinações\n",
    "prompts = [\n",
    "    \"O Brasil é famoso por sua culinária, especialmente o prato nacional chamado\",\n",
    "    \"A capital do Brasil é Brasília, que foi fundada em\",\n",
    "    \"O animal símbolo do Brasil é o\",\n",
    "    \"A Amazônia é conhecida por sua biodiversidade, incluindo espécies únicas como\"\n",
    "]\n",
    "\n",
    "# Gerando e exibindo textos\n",
    "for prompt in prompts:\n",
    "    texto_gerado = gerar_texto(prompt)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Texto gerado: {texto_gerado}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Alucinações em Modelos de Linguagem e Técnicas de Mitigação\n",
    "\n",
    "## Análise das Alucinações Geradas\n",
    "\n",
    "### 1. Prato nacional brasileiro\n",
    "- O modelo gerou uma mistura de espanhol e palavras sem sentido, sem mencionar nenhum prato brasileiro real.\n",
    "\n",
    "### 2. Fundação de Brasília\n",
    "- O modelo não forneceu uma data específica e misturou espanhol com inglês, sem oferecer informações factuais corretas.\n",
    "\n",
    "### 3. Animal símbolo do Brasil\n",
    "- O modelo não identificou nenhum animal específico e gerou uma sequência de palavras sem sentido, misturando português e espanhol.\n",
    "\n",
    "### 4. Espécies únicas da Amazônia\n",
    "- O modelo não mencionou nenhuma espécie real e produziu uma mistura de palavras em português e italiano, sem conteúdo factual.\n",
    "\n",
    "## Problemas Identificados\n",
    "- Mistura de idiomas (português, espanhol, inglês, italiano)\n",
    "- Falta de conhecimento específico sobre o Brasil\n",
    "- Geração de palavras sem sentido ou inexistentes\n",
    "- Incapacidade de fornecer informações factuais precisas\n",
    "\n",
    "## Técnicas para Evitar ou Mitigar Alucinações\n",
    "\n",
    "1. **Fine-tuning com Dados Específicos**\n",
    "   - Treinar o modelo com dados específicos e precisos sobre o Brasil pode melhorar a qualidade das respostas.\n",
    "\n",
    "2. **Retrieval-Augmented Generation (RAG)**\n",
    "   - Combinar o modelo de linguagem com uma base de conhecimento externa para fornecer informações factuais precisas.\n",
    "\n",
    "3. **Controle de Temperatura**\n",
    "   - Reduzir a temperatura (por exemplo, para 0.3-0.5) pode tornar as respostas mais conservadoras e menos propensas a alucinações.\n",
    "\n",
    "4. **Uso de Prompts mais Específicos**\n",
    "   - Fornecer mais contexto no prompt pode ajudar o modelo a gerar respostas mais precisas.\n",
    "\n",
    "5. **Pós-processamento e Filtragem**\n",
    "   - Implementar verificações para filtrar respostas que misturam idiomas ou contêm palavras sem sentido.\n",
    "\n",
    "6. **Modelos Multilíngues**\n",
    "   - Usar modelos treinados especificamente em português ou modelos multilíngues pode reduzir a mistura de idiomas.\n",
    "\n",
    "7. **Fact-Checking Automático**\n",
    "   - Implementar um sistema que verifica as informações geradas contra uma base de dados confiável.\n",
    "\n",
    "8. **Limitação de Tokens**\n",
    "   - Restringir o número de tokens gerados pode reduzir a chance de o modelo divagar e produzir conteúdo irrelevante.\n",
    "\n",
    "9. **Uso de Técnicas de Few-Shot Learning**\n",
    "   - Fornecer exemplos de respostas corretas no prompt pode guiar o modelo a gerar respostas mais precisas.\n",
    "\n",
    "10. **Modelos Especializados**\n",
    "    - Para tópicos específicos, como informações sobre o Brasil, considerar o uso de modelos treinados especificamente nesse domínio.\n",
    "\n",
    "Implementar uma combinação dessas técnicas pode ajudar significativamente a reduzir alucinações e melhorar a precisão das respostas geradas pelo modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoras_academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
