{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prevista: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Escolha do modelo\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# Carregamento do tokenizer e do modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Texto de entrada\n",
    "text = \"Eu odiei este produto! Nao Funciona de maneira alguma. \"\n",
    "\n",
    "# Tokeniza√ß√£o do texto\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Obten√ß√£o das previs√µes\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Processamento das sa√≠das\n",
    "logits = outputs.logits\n",
    "import torch\n",
    "predicted_class = torch.argmax(logits).item()\n",
    "print(f\"Classe prevista: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lise de Sentimento com BERT Multil√≠ngue\n",
    "\n",
    "## Bibliotecas Utilizadas\n",
    "\n",
    "### ü§ó Transformers\n",
    "- Biblioteca desenvolvida pela Hugging Face\n",
    "- Fornece acesso a milhares de modelos pr√©-treinados\n",
    "- Facilita o uso de arquiteturas transformer como BERT, GPT, T5\n",
    "- Principais componentes utilizados:\n",
    "  - `AutoTokenizer`: Tokeniza√ß√£o autom√°tica espec√≠fica para cada modelo\n",
    "  - `AutoModelForSequenceClassification`: Carregamento autom√°tico de modelos para classifica√ß√£o\n",
    "\n",
    "### PyTorch\n",
    "- Framework de deep learning\n",
    "- Usado para processamento tensorial e opera√ß√µes de ML\n",
    "- No c√≥digo: utilizado para processar os logits e obter a classe prevista\n",
    "\n",
    "## O Modelo BERT Multil√≠ngue para Sentimento\n",
    "\n",
    "### Caracter√≠sticas\n",
    "- Nome: `nlptown/bert-base-multilingual-uncased-sentiment`\n",
    "- Baseado na arquitetura BERT\n",
    "- Suporte multil√≠ngue (funciona em diversos idiomas)\n",
    "- Classifica√ß√£o em 5 n√≠veis (0 a 4):\n",
    "  - 0: Muito negativo\n",
    "  - 1: Negativo\n",
    "  - 2: Neutro\n",
    "  - 3: Positivo\n",
    "  - 4: Muito positivo\n",
    "\n",
    "### Funcionamento\n",
    "1. Tokeniza√ß√£o do texto em subpalavras\n",
    "2. Processamento atrav√©s das camadas BERT\n",
    "3. Classifica√ß√£o final atrav√©s de uma camada de classifica√ß√£o\n",
    "\n",
    "## Resultado Obtido\n",
    "No exemplo, a classe prevista foi 0 (muito negativo) para o texto:\n",
    "> \"Eu odiei este produto! Nao Funciona de maneira alguma.\"\n",
    "\n",
    "Este resultado √© coerente dado o conte√∫do claramente negativo da mensagem.\n",
    "\n",
    "## Aplica√ß√µes Pr√°ticas\n",
    "- An√°lise de satisfa√ß√£o de clientes\n",
    "- Monitoramento de redes sociais\n",
    "- An√°lise de reviews de produtos\n",
    "- Feedback de servi√ßos\n",
    "- Pesquisas de mercado\n",
    "\n",
    "## Poss√≠veis Melhorias\n",
    "\n",
    "### T√©cnicas\n",
    "1. Pr√©-processamento do texto:\n",
    "   - Corre√ß√£o ortogr√°fica\n",
    "   - Normaliza√ß√£o de acentua√ß√£o\n",
    "   - Remo√ß√£o de ru√≠dos\n",
    "\n",
    "2. P√≥s-processamento:\n",
    "   - Adicionar threshold de confian√ßa\n",
    "   - Implementar m√©dia m√≥vel para an√°lises sequenciais\n",
    "\n",
    "### Funcionais\n",
    "1. Adicionar interpretabilidade:\n",
    "```python\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "2. Implementar an√°lise de aspectos espec√≠ficos:\n",
    "```python\n",
    "def analyze_aspects(text, aspects):\n",
    "    results = {}\n",
    "    for aspect in aspects:\n",
    "        aspect_text = f\"Sobre {aspect}: {text}\"\n",
    "        results[aspect] = classifier(aspect_text)\n",
    "    return results\n",
    "```\n",
    "\n",
    "3. Adicionar tratamento de erros e valida√ß√µes:\n",
    "```python\n",
    "def predict_sentiment(text):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        raise ValueError(\"Texto n√£o pode ser vazio\")\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        return torch.argmax(outputs.logits).item()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro na predi√ß√£o: {str(e)}\")\n",
    "        raise\n",
    "```\n",
    "\n",
    "## Considera√ß√µes Finais\n",
    "O modelo demonstra boa capacidade de an√°lise de sentimento em portugu√™s, sendo especialmente √∫til por seu suporte multil√≠ngue. Para uso em produ√ß√£o, recomenda-se implementar as melhorias sugeridas e realizar uma avalia√ß√£o mais extensa com um conjunto de dados espec√≠fico do dom√≠nio de aplica√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoras_academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
