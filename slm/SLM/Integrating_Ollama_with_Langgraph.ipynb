{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-ollama) (0.3.1)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama)\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (0.1.121)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anderson/miniconda3/envs/scoras_academy/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.2.3)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.2.0 ollama-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install langgraph langchain langchain-community langchainhub langchain-core # install package\n",
    "#%pip install -U langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker exec -it ollama ollama run qwen2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Claro, vamos esclarecer o que é um LLM (Large Language Model) passo a passo:\\n\\n1. **Definição Básica**: Um LLM é um tipo de modelo de linguagem neural grande e complexo.\\n\\n2. **Escalabilidade**: \"Grande\" se refere ao tamanho do modelo, que contém bilhões ou trilhões de parâmetros. Isso permite que o modelo aprenda padrões mais complexos e contexto maior.\\n\\n3. **Treinamento em Grande Escala**: Estes modelos são treinados com grandes conjuntos de dados de texto, permitindo que eles geram textos semelhantes ao humano.\\n\\n4. **Capacidade de Entendimento Contextual**: LLMs têm a capacidade de entender e gerar texto contextualmente, o que significa que podem responder perguntas complexas, realizar tarefas criativas e gerar conversações naturais.\\n\\n5. **Versatilidade**: Estes modelos podem ser usados em uma variedade de tarefas, como tradução automática, resumo de artigos, geração de conteúdo criativo, assistentes virtuais personalizados, entre outros.\\n\\n6. **Desafios e Considerações Éticas**: Com a grande escala desses modelos vêm desafios éticos relacionados à privacidade dos dados utilizados no treinamento, ao potencial de produção de texto enganoso ou prejudicial, e aos custos associados ao processamento em larga escala.\\n\\nEntender os conceitos básicos de um LLM é importante para avaliar suas capacidades e limitações. Você gostaria de mais detalhes sobre algum aspecto específico?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Questão: {question}\n",
    "\n",
    "Resposta: Vamos pensar passo a passo.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"qwen2.5\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \" você pode explicar o que é o LLM?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Claro! Desenvolver um modelo de Machine Learning supervisionado envolve vários passos interconectados. Aqui está uma descrição passo a passo, linha por linha:\\n\\n1. **Entendendo o Problema e Definindo Objetivo**\\n   - Análise do problema business: Identifique o problema que você deseja resolver.\\n   - Definição de hipótese de solução: Formule como a solução pode ser implementada usando dados.\\n   - Estabelecimento dos objetivos de negócio: Defina metas específicas, mensuráveis e alinhadas com os objetivos da empresa.\\n\\n2. **Coleta de Dados**\\n   - Identificação do conjunto de dados necessários: Determine quais tipos de dados são necessários para treinar o modelo.\\n   - Coleta dos dados: Obtenha esses dados a partir de diversos fontes, como bancos de dados existentes, APIs, web scraping, etc.\\n\\n3. **Preparação e Limpeza dos Dados**\\n   - Verificação do conjunto de dados: Verifique se os dados estão completos, precisos e consistentes.\\n   - Tratamento de missing values (valores ausentes): Use técnicas adequadas para lidar com dados faltantes.\\n   - Normalização e padronização dos dados: Padronize as unidades ou escalonamento das variáveis se necessário.\\n\\n4. **Divisão do Conjunto de Dados**\\n   - Divida o conjunto de dados em conjuntos treinamento, validação e teste: Geralmente em proporções como 60% para treino, 20% para validação e 20% para teste.\\n   \\n5. **Seleção de Características (Feature Engineering)**\\n   - Criação e seleção de características relevantes: Identifique quais variáveis são mais importantes para o problema.\\n   - Engenharia de recursos: Criar novas características a partir das existentes, se necessário.\\n\\n6. **Escolha do Modelo**\\n   - Selecionar um modelo adequado: Baseado no tipo de problema (classificação, regressão), escolha o algoritmo apropriado.\\n   \\n7. **Treinamento do Modelo**\\n   - Treino do modelo: Ajuste o modelo com os dados de treinamento.\\n   - Tuning de hiperparâmetros: Ajuste parâmetros cruciais para melhorar o desempenho.\\n\\n8. **Validação e Avaliação do Modelo**\\n   - Avaliar o desempenho do modelo nos conjuntos de validação e teste: Use métricas relevantes como acurácia, F1-score, RMSE, etc.\\n   \\n9. **Ajuste Final do Modelo (Model Retuning)**\\n   - Baseado no desempenho inicial, faça ajustes finais: Pode ser necessário refinar os hiperparâmetros ou até mesmo escolher um novo modelo.\\n\\n10. **Implementação e Monitoramento**\\n    - Implementação: Integre o modelo no ambiente de produção.\\n    - Monitoramento do modelo: Verifique continuamente o desempenho do modelo em uso real, ajuste conforme necessário.\\n\\n11. **Documentação e Relatórios**\\n    - Documentar todo o processo: Manter registros detalhados do projeto para fins futuros ou auditoria.\\n    - Preparar relatórios: Crie relatórios para apresentar a solução ao time de negócios.\\n\\nEssa é uma visão geral passo a passo do desenvolvimento de um modelo de Machine Learning supervisionado. Cada etapa pode ser mais complexa e requerer habilidades específicas, mas essas são as linhas básicas do processo.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\" Pode me detalhar linha por linha como se desenvolve um modelo de machine learning supervisionado?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\":\"Pode me resolver a equação 2x+3=10?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoras_academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
